{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pojXCIlVJ_So"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wXsa8vFKCju",
        "outputId": "b2a6c2cc-580f-4a2f-85f7-846f02b2d59d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Ashupics', 'Dhruvpics', 'ivanpics', 'mayankpics', 'prathampics', 'Tirthpics']\n"
          ]
        }
      ],
      "source": [
        "# Define the path to your dataset directory, where each subdirectory represents an individual.\n",
        "dataset_dir = \"C:/Users/mehta/Desktop/Dl_Dataset\"\n",
        "contents = os.listdir(dataset_dir)\n",
        "print(contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tONZQCgNKRLZ"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store images and labels.\n",
        "images = []\n",
        "labels = []\n",
        "names = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUvhF9SWKY2I"
      },
      "outputs": [],
      "source": [
        "# Iterate through the subdirectories (individuals) in the dataset directory.\n",
        "for subdir in os.listdir(dataset_dir):\n",
        "    if os.path.isdir(os.path.join(dataset_dir, subdir)):\n",
        "        # Iterate through the images in each subdirectory.\n",
        "        for filename in os.listdir(os.path.join(dataset_dir, subdir)):\n",
        "            img_path = os.path.join(dataset_dir, subdir, filename)\n",
        "\n",
        "            # Load and preprocess each image (e.g., resize to a fixed size, normalize pixel values).\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (512, 512))  # Resize to a fixed size (adjust as needed).\n",
        "            img = img / 255.0  # Normalize pixel values to the range [0, 1].\n",
        "\n",
        "            # Append the preprocessed image to the images list.\n",
        "            images.append(img)\n",
        "\n",
        "            # Append the corresponding label (class or identity).\n",
        "            labels.append(subdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj70VsS5C-fk",
        "outputId": "c0ee65e6-0114-4d36-e2d6-2153c6098f39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bbGD6JEgczj"
      },
      "outputs": [],
      "source": [
        "image=np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6g9r5r_KjDM"
      },
      "outputs": [],
      "source": [
        "# Convert labels to NumPy array.\n",
        "labels = np.array(labels)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "label = encoder.fit_transform(labels)\n",
        "label = np.array([[i] for i in label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9SL_kIBKq_n"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(image, label, test_size=0.5, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPleLAGUf83n",
        "outputId": "2c8eaffb-271f-42b2-ca06-aaee6a1b5f94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 512, 512, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDAJjLOwKyvP"
      },
      "outputs": [],
      "source": [
        "# Step 1: Build the CNN for feature extraction\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),  # Adding dropout with a rate of 0.5 (you can adjust the rate as needed)\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Adding dropout with a rate of 0.5\n",
        "    layers.Dense(len(np.unique(labels)), activation='softmax')  # Output layer with the number of classes\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kifWyCzK3rp"
      },
      "outputs": [],
      "source": [
        "# Compile the CNN model.\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv_PcTgDK6lA",
        "outputId": "73dd480f-5a25-4070-9aae-65bddb5a38aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 41s 4s/step - loss: 20.6132 - accuracy: 0.2667\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 32s 4s/step - loss: 1.2881 - accuracy: 0.5333\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 42s 5s/step - loss: 1.0860 - accuracy: 0.5833\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 33s 4s/step - loss: 0.7107 - accuracy: 0.7333\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.4843 - accuracy: 0.8833\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.2904 - accuracy: 0.9167\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.2321 - accuracy: 0.9167\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.4144 - accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.1526 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 30s 4s/step - loss: 0.0929 - accuracy: 0.9667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1f46b6a92e0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 2: Train the CNN\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjwVFcoiK9U8",
        "outputId": "045b0e4e-d758-4c00-af26-12fda6b30efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 960ms/step\n",
            "['Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics', 'Ashupics']\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Extract features using the trained CNN\n",
        "y_pred = cnn_model.predict(X_test)\n",
        "def get_predicted_classes(prediction, class_labels):\n",
        "    predictions = np.array([i for i in prediction])\n",
        "    predicted_classes = []\n",
        "    for pred in predictions:\n",
        "      max_index = np.argmax(pred)\n",
        "      predicted_class = class_labels[max_index]\n",
        "      predicted_classes.append(predicted_class)\n",
        "    print(predicted_classes)\n",
        "    return predicted_classes\n",
        "\n",
        "pred_classes_index = get_predicted_classes(y_pred, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeOUDe6DKaeZ",
        "outputId": "2be04f1f-0cb7-4517-b361-e962fae0cff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 189ms/step\n",
            "[[4.1495825e-38 2.0363412e-23 1.2361975e-22 2.3189296e-24 2.4787792e-34\n",
            "  1.0000000e+00]]\n",
            "['Tirthpics']\n"
          ]
        }
      ],
      "source": [
        "def get_predicted_classes(prediction, class_labels):\n",
        "    predicted_classes = []\n",
        "    for pred in prediction:\n",
        "        max_index = np.argmax(pred)\n",
        "        predicted_class = class_labels[max_index]\n",
        "        predicted_classes.append(predicted_class)\n",
        "    return predicted_classes\n",
        "\n",
        "test = cv2.imread(\"C:/Users/mehta/Desktop/Dl_Dataset/prathampics/WIN_20230921_23_17_07_Pro.jpg\")\n",
        "test = cv2.resize(test, (512, 512))\n",
        "test = test / 255.0  # Normalize pixel values if your model expects this.\n",
        "\n",
        "# Make predictions using your CNN model.\n",
        "predictions = cnn_model.predict(np.array([test]))\n",
        "print(predictions)\n",
        "# Get the predicted classes.\n",
        "predicted_classes = get_predicted_classes(predictions, contents)\n",
        "print(predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRsFyVXD7JaC",
        "outputId": "46b15c2b-369d-47ff-ff89-14807d7b1894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Photo saved as C:\\Users\\mehta\\Desktop\\captured_photo.jpg\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Get the user's home directory and desktop path\n",
        "home_directory = os.path.expanduser(\"~\")\n",
        "desktop_path = os.path.join(home_directory, \"Desktop\")\n",
        "\n",
        "# Initialize the camera\n",
        "camera = cv2.VideoCapture(0)  # 0 represents the default camera (usually the built-in webcam)\n",
        "\n",
        "# Check if the camera is opened successfully\n",
        "if not camera.isOpened():\n",
        "    print(\"Error: Could not open camera.\")\n",
        "    exit()\n",
        "\n",
        "# Capture a photo\n",
        "ret, frame = camera.read()\n",
        "\n",
        "# Check if the capture was successful\n",
        "if not ret:\n",
        "    print(\"Error: Could not capture a photo.\")\n",
        "else:\n",
        "    # Save the captured photo to the desktop\n",
        "    file_name = os.path.join(desktop_path, \"captured_photo.jpg\")\n",
        "    cv2.imwrite(file_name, frame)\n",
        "    print(f\"Photo saved as {file_name}\")\n",
        "\n",
        "# Release the camera\n",
        "camera.release()\n",
        "\n",
        "# Close any OpenCV windows that may have opened\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lbF18M2B9dW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}